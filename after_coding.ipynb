{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import pandas as pd\n",
    "from pandas.testing import assert_series_equal\n",
    "import datetime\n",
    "\n",
    "pd.options.display.float_format = '{:.1f}'.format\n",
    "\n",
    "def uniq(seq):\n",
    "    return list(dict.fromkeys(seq))\n",
    "\n",
    "accept_to_answer_column = 'B'\n",
    "applicable_check_column = 'C'\n",
    "\n",
    "# Assign A,B,C,... column names to source data frame.\n",
    "\n",
    "df = pd.read_csv('./data/source.csv', na_values=[''])\n",
    "questions: pd.Series = pd.read_csv('./config/questions.csv', index_col=0).squeeze()\n",
    "col_names = questions.index.to_series()\n",
    "questions_in_source = pd.Series(df.columns).replace(regex=r'\\.[0-9]+$', value=r'')\n",
    "assert_series_equal(questions, questions_in_source, check_names=False, check_index=False)\n",
    "\n",
    "col_name_df = questions.copy()\n",
    "col_name_df = col_names + ': ' + col_name_df\n",
    "\n",
    "df.columns = col_names\n",
    "df.index += 1\n",
    "df.index.name = '回答番号'\n",
    "\n",
    "\n",
    "# Find rows which is before start or declined\n",
    "drop_candidates = df[((pd.to_datetime(df['A']).dt.tz_localize('+09:00')) <= datetime.datetime.fromisoformat('2024-11-01T00:00:00+09:00')) | (df['B'] != '了承して、回答する')]\n",
    "drop_candidates.columns = col_names + ': ' + questions\n",
    "drop_candidates.to_csv('./out/drop_candidates.csv')\n",
    "\n",
    "# Find rows which does not meet requirement\n",
    "requirement_drop_candidates = df[df['C'] != 'はい']\n",
    "requirement_drop_candidates.columns = col_names + ': ' + questions\n",
    "requirement_drop_candidates.to_csv('./out/requirement_drop_candidates.csv')\n",
    "\n",
    "\n",
    "ac_drop_df = pd.read_csv('./data/after_codings/drops.csv')\n",
    "drop_index = pd.Index(ac_drop_df['回答番号']).sort_values()\n",
    "drop_df = df.loc[drop_index, :]\n",
    "df.drop(drop_index, inplace=True)\n",
    "assert(df[accept_to_answer_column].unique().tolist() == ['了承して、回答する'])\n",
    "\n",
    "# Convert float to int with NA\n",
    "for column in df:\n",
    "    if df[column].dtype.kind == 'f':\n",
    "        df[column] = df[column].astype('Int64')\n",
    "\n",
    "with_column_names_df = df.copy()\n",
    "with_column_names_df.columns = col_names + ': ' + questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup choices_df\n",
    "# choices_df contains multiple candidates of choice indexed by column name\n",
    "choices_df = pd.read_csv('./config/choices.csv')\n",
    "assert_series_equal(choices_df['設問文章'], questions[questions != \"タイムスタンプ\"], check_names=False, check_index=False)\n",
    "choices_df.index = col_names.drop(index=questions[questions == \"タイムスタンプ\"].index).values\n",
    "choices_df['選択肢'] = choices_df['選択肢'].str.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output raw data with modified column names\n",
    "\n",
    "import os\n",
    "\n",
    "os.makedirs('out/images', 0o755, exist_ok=True)\n",
    "\n",
    "with_column_names_df.to_csv('out/raw.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode multiple choices into list, extract other answers\n",
    "\n",
    "other_answer_to_indices_dict_by_col = { col: {} for col in choices_df[choices_df['その他回答'] == 1].index }\n",
    "\n",
    "# single choice cols\n",
    "for column in choices_df.loc[(choices_df['複数回答'] != 1) & (choices_df['その他回答'] == 1), :].index:\n",
    "    other_answer_to_indices_dict_by_col[column] = df.groupby(column).apply(lambda x: list(x.index)).drop(choices_df.loc[column, '選択肢'], errors='ignore').to_dict()\n",
    "\n",
    "# multi choice cols, with list\n",
    "multi_choice_answers_df = df[choices_df.loc[choices_df['複数回答'] == 1, :].index].copy()\n",
    "for column in multi_choice_answers_df.columns:\n",
    "    choices_set = uniq(choices_df.loc[column, '選択肢'])\n",
    "\n",
    "    def split_choices(row):\n",
    "        text = row.values[0]\n",
    "        if not isinstance(text, str):\n",
    "            return []\n",
    "        attrs = text.split(', ')\n",
    "        ret = []\n",
    "        for i, attr in enumerate(attrs):\n",
    "            if attr in choices_set:\n",
    "                ret.append(attr)\n",
    "            else:\n",
    "                # Join texts after first other answer text (users can input exact ', ')\n",
    "                rem = ', '.join(attrs[i:])\n",
    "                ret.append(rem)\n",
    "                dic = other_answer_to_indices_dict_by_col[column]\n",
    "                dic.setdefault(rem, [])\n",
    "                dic[rem].append(row.name)\n",
    "                break\n",
    "        # filter empty text\n",
    "        ret = [choice for choice in ret if choice]\n",
    "        return ret\n",
    "\n",
    "    multi_choice_answers_df[column] = multi_choice_answers_df[column].to_frame().apply(split_choices, axis='columns')\n",
    "\n",
    "col_other_answer_and_count_tuple_tuple = map(lambda col_dict: (col_dict[0], sorted(col_dict[1].items(), key=lambda t: len(t[1]), reverse=True)), other_answer_to_indices_dict_by_col.items())\n",
    "\n",
    "out_other_answers_df = pd.DataFrame(col_other_answer_and_count_tuple_tuple, columns=['列番号', 'group']).explode('group').reset_index()\n",
    "out_other_answers_df = pd.concat([out_other_answers_df['列番号'], pd.DataFrame(map(lambda item: (item[0], len(item[1]), item[1]), out_other_answers_df['group'].tolist()), columns=['回答文字列', '出現回数', '回答番号'])], axis='columns')\n",
    "out_other_answers_df = out_other_answers_df.explode('回答番号')\n",
    "out_other_answers_df.insert(1, '設問文章', choices_df.loc[out_other_answers_df['列番号'], '設問文章'].values)\n",
    "out_other_answers_all_df = pd.merge(out_other_answers_df, with_column_names_df, how='left', left_on='回答番号', right_index=True)\n",
    "out_other_answers_all_df.to_csv('out/other_answers.csv', index=False)\n",
    "\n",
    "os.makedirs('out/other_answers', 0o755, exist_ok=True)\n",
    "\n",
    "for column, group in out_other_answers_df.groupby('列番号'):\n",
    "    question: str = questions[column]\n",
    "    normalized_question = question.replace('/', '_')\n",
    "    # TODO: 選択肢一覧をつける\n",
    "    group.to_csv(f'out/other_answers/{column}_{normalized_question}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "# Find duplicated\n",
    "\n",
    "dup_groups_list: List[pd.DataFrame] = []\n",
    "\n",
    "free_text_cols = choices_df[choices_df['自由記述'] == 1].index\n",
    "non_free_text_cols = choices_df.index.drop(free_text_cols)\n",
    "\n",
    "dup_all_rows_df = df[df.duplicated(non_free_text_cols, keep=False)][non_free_text_cols].dropna(how='all')\n",
    "dup_all_rows_df.sort_values(non_free_text_cols.tolist())\n",
    "dup_all_group_df = dup_all_rows_df.iloc[:, 0:0].copy()\n",
    "dup_all_group_df['回答'] = '自由記述以外のすべて'\n",
    "dup_all_group_df.insert(0, '列番号', '自由記述以外のすべて')\n",
    "dup_all_group_df.reset_index(inplace=True)\n",
    "dup_groups_list.append(dup_all_group_df)\n",
    "\n",
    "dup_unique_df = df.drop(dup_all_rows_df.index)\n",
    "\n",
    "for column in free_text_cols:\n",
    "    dup_series: pd.Series = dup_unique_df[dup_unique_df.duplicated(column, keep=False)][column].dropna(how='all')\n",
    "    dup_groups = dup_series.sort_values()\n",
    "    dup_group_df = dup_groups.to_frame()\n",
    "    dup_group_df.columns = ['回答']\n",
    "    dup_group_df.insert(0, '列番号', column)\n",
    "    dup_group_df.reset_index(inplace=True)\n",
    "    dup_groups_list.append(dup_group_df)\n",
    "\n",
    "out_dup_df = pd.concat(dup_groups_list, ignore_index=True)\n",
    "out_dup_df = pd.merge(out_dup_df, with_column_names_df, how='left', left_on='回答番号', right_index=True)\n",
    "out_dup_df.to_csv('out/duplicates.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclusive choices\n",
    "\n",
    "\n",
    "excl_config_df = pd.read_csv('./config/exclusive_choices.csv')\n",
    "\n",
    "other_answer_keyword = \"他の選択肢\"\n",
    "\n",
    "excl_entry_list = []\n",
    "\n",
    "for index, row in excl_config_df.iterrows():\n",
    "    column = row['設問番号']\n",
    "    before_choice = row['他の選択肢と押すと矛盾する選択肢']\n",
    "    if pd.isna(before_choice):\n",
    "        continue\n",
    "    choice_list = choices_df.loc[column, '選択肢']\n",
    "    if not before_choice in choice_list:\n",
    "        raise Exception(f\"\\\"{before_choice}\\\" is not a valid choice, valid choices: {choice_list}\")\n",
    "\n",
    "    matched_series = df.loc[multi_choice_answers_df[column].apply(lambda arr: before_choice in arr and len(arr) >= 2), column]\n",
    "\n",
    "    if row['残す選択肢'] == other_answer_keyword:\n",
    "        after_series = multi_choice_answers_df.loc[matched_series.index, column].apply(lambda arr: ','.join([x for x in arr if x != before_choice]))\n",
    "    else:\n",
    "        if row['残す選択肢'] not in choice_list:\n",
    "            raise Exception(f\"\\\"{row['残す選択肢']}\\\" is not a valid choice, valid choices: {choice_list}\")\n",
    "        after_series = [row['残す選択肢']] * len(matched_series)\n",
    "\n",
    "    excl_entry_df = pd.DataFrame({\n",
    "        '回答番号': matched_series.index,\n",
    "        '設問番号': [column] * len(matched_series),\n",
    "        '他の選択肢と押すと矛盾する選択肢': [before_choice] * len(matched_series),\n",
    "        '変更前': matched_series.values,\n",
    "        '変更後': after_series\n",
    "    })\n",
    "    excl_entry_list.append(excl_entry_df)\n",
    "\n",
    "if len(excl_entry_list) > 0:\n",
    "    out_excl_df = pd.concat(excl_entry_list, ignore_index=True)\n",
    "    out_excl_df.to_csv('out/exclusives.csv', index=False)\n",
    "else:\n",
    "    out_excl_df = pd.DataFrame(columns=['回答番号', '設問番号', '他の選択肢と押すと矛盾する選択肢', '変更前', '変更後'])\n",
    "    out_excl_df.to_csv('out/exclusives.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect age contradictions\n",
    "\n",
    "current_age_column = 'D'\n",
    "# TODO: 設定ファイルにする\n",
    "answer_age_columns = ['AK', 'AL', 'AO']\n",
    "\n",
    "has_age_contradictions_df = df[answer_age_columns].gt(df[current_age_column], axis='index')\n",
    "\n",
    "out_age_contra_df = has_age_contradictions_df[has_age_contradictions_df.any(axis='columns')].copy()\n",
    "out_age_contra_df = df.loc[out_age_contra_df.index, answer_age_columns][out_age_contra_df]\n",
    "out_age_contra_df.insert(0, 'D', df.loc[out_age_contra_df.index, current_age_column])\n",
    "# TODO: add question text to columns\n",
    "out_age_contra_df.columns = col_name_df.loc[[current_age_column] + answer_age_columns].values\n",
    "out_age_contra_df.astype('Int64').to_csv('out/age_contradictions.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No changes for column D\n",
      "Warning: No changes for column AL\n",
      "Warning: Change for index 62 of column AQ causes duplication, truncated\n",
      "Warning: Change for index 2170 of column BN causes duplication, truncated\n",
      "Warning: Change for index 283 of column BR causes duplication, truncated\n",
      "Warning: Change for index 1250 of column BR causes duplication, truncated\n",
      "Warning: Change for index 2436 of column BR causes duplication, truncated\n"
     ]
    }
   ],
   "source": [
    "# After codings\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import itertools\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "from typing import Optional\n",
    "from typing import List\n",
    "\n",
    "# Read changes\n",
    "\n",
    "changes_dir = './data/after_codings/changes'\n",
    "\n",
    "@dataclass\n",
    "class ChangeSet:\n",
    "    column: str\n",
    "    df: pd.DataFrame\n",
    "    file_path: str\n",
    "    exact_for_multiple: bool = False\n",
    "\n",
    "change_sets: List[ChangeSet] = []\n",
    "\n",
    "for file_path in sorted(glob.glob(changes_dir + '/**/*', recursive=True)):\n",
    "    if os.path.isdir(file_path):\n",
    "        continue\n",
    "\n",
    "    if file_path.endswith('.csv'):\n",
    "        change_def_df = pd.read_csv(file_path)\n",
    "    elif file_path.endswith('.xlsx'):\n",
    "        change_def_df = pd.read_excel(file_path)\n",
    "    else:\n",
    "        raise ValueError(f'Unsupported file type: {file_path}')\n",
    "\n",
    "    has_valid_change_column = False\n",
    "\n",
    "    if '列番号' in change_def_df.columns:\n",
    "        # 列番号,回答文字列,回答番号,変更後\n",
    "        grouped = change_def_df.groupby('列番号')\n",
    "        for column, change_set in grouped:\n",
    "            exact_for_multiple = False\n",
    "            if '変更前（完全一致）' in change_set.columns:\n",
    "                change_set = change_set[['回答番号', '変更前（完全一致）', '変更後']].set_index('回答番号')\n",
    "                exact_for_multiple = True\n",
    "            else:\n",
    "                change_set = change_set[['回答番号', '回答文字列', '変更後']].set_index('回答番号')\n",
    "            change_set.columns = ['修正前', '修正後']\n",
    "            change_set = change_set[change_set['修正後'] != '変更なし']\n",
    "            change_set.dropna(how='all', inplace=True)\n",
    "            change_sets.append(ChangeSet(column=column, df=change_set, file_path=file_path, exact_for_multiple=exact_for_multiple))\n",
    "    else:\n",
    "        # 回答番号,A: ***,修正後A,B: ***,修正後B,...\n",
    "        for after_col in change_def_df.columns:\n",
    "            if not after_col.startswith('修正後'):\n",
    "                continue\n",
    "            has_valid_change_column = True\n",
    "\n",
    "            column = after_col.replace('修正後', '')\n",
    "            before_col = column\n",
    "            if before_col not in change_def_df.columns:\n",
    "                before_col = column + ': ' + questions[column]\n",
    "            if before_col not in change_def_df.columns:\n",
    "                raise ValueError(f'Column {column} or {before_col} not found in {file_path}')\n",
    "\n",
    "            change_set = change_def_df[['回答番号', before_col, after_col]].copy().set_index('回答番号')\n",
    "            change_set.columns = ['修正前', '修正後']\n",
    "            change_set = change_set[change_set['修正後'] != '変更なし']\n",
    "            change_set.dropna(how='all', inplace=True)\n",
    "            change_sets.append(ChangeSet(column=column, df=change_set, file_path=file_path))\n",
    "\n",
    "        if not has_valid_change_column:\n",
    "            raise ValueError(f'No valid change column prefixed with \"修正後\" found in {file_path}')\n",
    "\n",
    "\n",
    "# Apply changes\n",
    "\n",
    "ac_data_df = df.copy()\n",
    "# Multi choice answers are stored as list of strings in this data frame\n",
    "ac_multi_choice_df = multi_choice_answers_df.copy()\n",
    "\n",
    "for change_set in change_sets:\n",
    "    column = change_set.column\n",
    "    if change_set.df.empty:\n",
    "        print(f'Warning: No changes for column {column}')\n",
    "        continue\n",
    "\n",
    "    if change_set.df['修正前'].isna().any():\n",
    "        print(f'Error: empty cell found in {change_set.file_path} for before cell of {column}')\n",
    "    if change_set.df['修正後'].isna().any():\n",
    "        print(f'Error: empty cell found in {change_set.file_path} for after cell of {column}')\n",
    "\n",
    "    if change_set.df.index.has_duplicates:\n",
    "        duplicates = ', '.join(map(str, change_set.df.index[change_set.df.index.duplicated()]))\n",
    "        raise ValueError(f'Column {column} has duplicated changes for same index ({duplicates})')\n",
    "\n",
    "    if column in ac_multi_choice_df.columns:\n",
    "\n",
    "        # Support exploding to multiple choices\n",
    "        # TODO: do not modify shared change_set.df\n",
    "        change_set.df['修正後'] = change_set.df['修正後'].str.split(re.compile(r', ?'))\n",
    "\n",
    "        for index, row in change_set.df.iterrows():\n",
    "            before_list = ac_multi_choice_df.loc[index, column]\n",
    "\n",
    "            if change_set.exact_for_multiple:\n",
    "                before_list_str = ', '.join(before_list) # 回答文字列なので、スペースありのカンマで分解している\n",
    "                if before_list_str != row['修正前']:\n",
    "                    print(f'Error: cell [{column},{index}]: \"{row[\"修正前\"]}\" does not match (actual \"{before_list}\", changing to {row[\"修正後\"]}) (file_path: \"{change_set.file_path}\")')\n",
    "                    continue\n",
    "                ac_multi_choice_df.loc[index, column] = row['修正後']\n",
    "            else:\n",
    "                # Edit only single element in multiple choices, not entire answer\n",
    "\n",
    "                if row['修正前'] not in map(str.strip, before_list):\n",
    "                    print(f'Error: cell [{column},{index}]: \"{row[\"修正前\"]}\" not found (actual {before_list}, changing to {row[\"修正後\"]}) (file_path: \"{change_set.file_path}\")')\n",
    "                    continue\n",
    "                updated_choices = list(itertools.chain.from_iterable([row['修正後'] if x.strip() == row['修正前'] else [x] for x in before_list]))\n",
    "                if len(updated_choices) != len(set(updated_choices)):\n",
    "                    print(f'Warning: Change for index {index} of column {column} causes duplication, truncated')\n",
    "                ac_multi_choice_df.loc[index, column] = uniq(updated_choices)\n",
    "\n",
    "    else:\n",
    "        # Not to allow same index to be changed multiple times, for safety\n",
    "        if change_set.df.index.has_duplicates:\n",
    "            duplicates = ', '.join(map(str, change_set.df.index[change_set.df.index.duplicated()]))\n",
    "            raise ValueError(f'Column {column} has duplicated changes for same index ({duplicates})')\n",
    "\n",
    "        before = ac_data_df[column][change_set.df.index]\n",
    "        if pd.api.types.is_string_dtype(before):\n",
    "            assert_series_equal(before.str.strip(), change_set.df['修正前'].str.strip(), check_names=False, check_dtype=False, check_index=False)\n",
    "        else:\n",
    "            assert_series_equal(before, change_set.df['修正前'], check_names=False, check_dtype=False, check_index=False)\n",
    "        ac_data_df.loc[change_set.df.index, column] = change_set.df['修正後']\n",
    "\n",
    "# Remove rows which does not meet requirement\\n\",\n",
    "ac_requirement_drop_index =  ac_data_df[ac_data_df[applicable_check_column] == 'いいえ'].index\n",
    "ac_data_df.drop(ac_requirement_drop_index, inplace=True)\n",
    "assert(ac_data_df[applicable_check_column].unique().tolist() == ['はい'])\n",
    "\n",
    "# Strip text in free text answers\n",
    "for col in choices_df[(choices_df['その他回答'] == 1) | (choices_df['自由記述'] == 1)].index:\n",
    "    if ac_data_df[col].dtype != 'object':\n",
    "        print(f\"Warning: column {col} is not object type. Maybe empty free text column?\")\n",
    "    else:\n",
    "        ac_data_df[col] = ac_data_df[col].str.strip(' 　')\n",
    "for col in ac_multi_choice_df:\n",
    "    ac_multi_choice_df[col] = ac_multi_choice_df[col].apply(lambda arr: list(map(lambda s: s.strip(' 　'), arr)))\n",
    "\n",
    "out_ac_df = ac_data_df.copy()\n",
    "for column, series in ac_multi_choice_df.items():\n",
    "    out_ac_df[column] = series.str.join(', ')\n",
    "assert_series_equal(out_ac_df.columns.to_series(), col_names)\n",
    "out_ac_df.columns = col_names + ': ' + questions\n",
    "out_ac_df.to_csv('out/after_coded.csv')\n",
    "\n",
    "out_ac_serialized_df = ac_data_df.copy()\n",
    "out_ac_serialized_df.update(ac_multi_choice_df)\n",
    "assert_series_equal(out_ac_serialized_df.columns.to_series(), col_names)\n",
    "out_ac_serialized_df.reset_index(inplace=True)\n",
    "out_ac_serialized_df.to_feather('out/after_coded.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_drop_df = pd.concat([drop_df, df.loc[ac_requirement_drop_index, :]]).sort_index()\n",
    "out_drop_df.columns = col_names + ': ' + questions\n",
    "out_drop_df.to_csv('out/drop.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
